{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from convolutional import ConvolutionalLayer\n",
    "from dense import DenseLayer\n",
    "from maxpool import MaxpoolLayer\n",
    "from flatten import FlattenLayer\n",
    "from softmax import SoftmaxLayer\n",
    "from sigmoid import SigmoidLayer\n",
    "from loss import LossLayer\n",
    "from test_utils import plot_loss_history, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.images\n",
    "labels = np.array([[0 if x!=i else 1 for x in range(10)] for i in digits.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scale_inputs(X):\n",
    "    return np.array([(X[i] - np.mean(X[i]))/np.std(X[i]) for i in range(X.shape[0])])\n",
    "def min_max_scale_inputs(X):\n",
    "    return np.array([(X[i] - np.min(X[i]))/(np.max(X[i]) - np.min(X[i])) for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSpec1(Model):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        X_train = min_max_scale_inputs(X_train)\n",
    "        X_test = min_max_scale_inputs(X_test)\n",
    "        super().__init__(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            batch_size=40,\n",
    "            num_epochs=15\n",
    "        )     \n",
    "        self.conv = ConvolutionalLayer(\n",
    "            kernel_size=(2, 2), num_outputs=1, zero_padding=False, learning_rate=0.01\n",
    "        )\n",
    "        self.maxp = MaxpoolLayer(\n",
    "            kernel_size=(1, 1), zero_padding=True\n",
    "        )\n",
    "        self.flat = FlattenLayer()\n",
    "        self.dense = DenseLayer(\n",
    "            num_neurons=10, learning_rate=0.01\n",
    "        )\n",
    "        self.activation = SoftmaxLayer()\n",
    "        self.loss = LossLayer(loss_method=\"categorical_crossentropy\")\n",
    "        self.model = [\n",
    "            ([\"input\", \"multi_output\"], self.conv), \n",
    "            ([\"hidden\"], self.maxp),\n",
    "            ([\"hidden\"], self.flat),\n",
    "            ([\"hidden\"], self.dense),\n",
    "            ([\"hidden\"], self.activation),\n",
    "            ([\"loss\"], self.loss)\n",
    "        ]\n",
    "        self.reverse_model = list(reversed(self.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSpec2(Model):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        X_train = normalize_scale_inputs(X_train)\n",
    "        X_test = normalize_scale_inputs(X_test)\n",
    "        super().__init__(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            batch_size=40,\n",
    "            num_epochs=15\n",
    "        )\n",
    "        self.conv = ConvolutionalLayer(\n",
    "            kernel_size=(2, 2), num_outputs=1, zero_padding=False, learning_rate=0.01\n",
    "        )\n",
    "        self.maxp = MaxpoolLayer(\n",
    "            kernel_size=(1, 1), zero_padding=True\n",
    "        )\n",
    "        self.flat = FlattenLayer()\n",
    "        self.dense1 = DenseLayer(\n",
    "            num_neurons=5, learning_rate=0.01\n",
    "        )\n",
    "        self.sigmoid = SigmoidLayer()\n",
    "        self.dense2 = DenseLayer(\n",
    "            num_neurons=10, learning_rate=0.01\n",
    "        )\n",
    "        self.activation = SoftmaxLayer()\n",
    "        self.loss = LossLayer(loss_method=\"categorical_crossentropy\")\n",
    "        self.model = [\n",
    "            ([\"input\", \"multi_output\"], self.conv),\n",
    "            ([\"hidden\"], self.maxp),\n",
    "            ([\"hidden\"], self.flat),\n",
    "            ([\"hidden\"], self.dense2),\n",
    "            ([\"hidden\"], self.activation),\n",
    "            ([\"loss\"], self.loss)\n",
    "        ]\n",
    "        self.reverse_model = list(reversed(self.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ModelSpec1(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.9815325131975485\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.9416089401462204\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  3.2128904274500583\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.87087992893925\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.9661196017157336\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.8759050844045477\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.844698683584465\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  3.0706701773537053\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.8889422481726674\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.7606671120925474\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.6438263608760653\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  3.0552569447064655\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.852828199333173\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.663502442305981\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.960739569723167\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.576681319444021\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.7527453156095136\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.5483598508498826\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.6129163076240203\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.5686360490883464\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.7996456147528903\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.512241576709928\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.9044236403880257\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.7341107100384106\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.5145938746298446\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.793248525489544\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.8508135170149047\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.582069168478859\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.452763264423926\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.696379252753352\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.614254990927188\n",
      "Training epoch 2 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.50384724978192\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.5162379425127055\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.8721793012493855\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.6544487768753586\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.6729224742415845\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.6566620510897887\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.7004431300376552\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.9662823163766188\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.6933893195424594\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.607428388646193\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.5446013779674805\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.8713598937774707\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.737263401443549\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.4958941083269472\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.872281480612938\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.5132577566416603\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.644173785435003\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.4145205972831882\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.520778854659671\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.4978927480832733\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.6543378734058556\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.3695424410977806\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.7911446081179916\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.6164050547060076\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.4418385026329466\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.685550625267206\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.7237706790641165\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.5012404051402286\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.305630269444665\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.5502838429845216\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.5462306203632474\n",
      "Training epoch 3 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.4082425304804103\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.404731098291287\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.7177982570490116\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.5563182742227744\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.546214849600518\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.539766180379673\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.5738263119219695\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.8366448032715494\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.562359311161384\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.493053670635711\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.453773416560898\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.7027753275234137\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.608257061772582\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.382900345369727\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.7334191449312275\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.450298808480176\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.5310295018222977\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.303995159921678\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.4362937457812577\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.4122326683464945\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.509367856124771\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.2685292152893446\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.637148463247782\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.4843327826551445\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.361025007750088\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.54814931123284\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.577634211707707\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.418684633674554\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.1940052382414357\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.3968089469534393\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.4626667307315997\n",
      "Training epoch 4 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.307912170882858\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.2906481926525037\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.5360892770640056\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.4288250039317862\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.410696185847744\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.415697385824928\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.4192907004066546\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.6563061154526353\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.4231020722838155\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.3756795464055616\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.352632993692379\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.5071166572854344\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.461836172555781\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.280687751014009\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.5459916418420363\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.3785929862078916\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.397619328606195\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.2049542545954184\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.354723618157813\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.3207089254621933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.358866732117426\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.201318533576444\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.45535721203792\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.3571947135833873\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.2855922162796\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.40064433744327\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.429231703995918\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.3528639278880483\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.130102074001074\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.261973666266715\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.3719263223028926\n",
      "Training epoch 5 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.227295670088504\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.2013157683530915\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.368767000409725\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.2950517407376148\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.2934171952556297\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.319504013773386\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.279432224645413\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.4649580361825776\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.315347635014718\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.2960171959753497\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.2729012057614115\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.3418071317093743\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.348721694475841\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.223600817633569\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.370553212116679\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.3150113967515624\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.2843154525986296\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.1587673376708474\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.3032848985426906\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.2553500174496564\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.2661193584193917\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.1850193759404366\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.318537745381024\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.281333457636107\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.2411610830692497\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.299467064686275\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.3416663139654994\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.3189329960212284\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.120739556351916\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.1935871651210697\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.3232264301372245\n",
      "Training epoch 6 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.1881799584838304\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.160752470869236\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.2750489221614787\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.2026637302536556\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.228490495306837\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.2746219228927753\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.199171690445502\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.341148111623094\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.269787589250703\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.2601323253491588\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.227127994251749\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.2571880301567218\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.2926084247485883\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.203922162289269\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.270849747243426\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.26942218264638\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.2186253317796405\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.1414999878725576\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.2737838964359356\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.2137335150256234\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.232493508972822\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.176935479317879\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.2493578955616678\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.240359667111836\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.2102725953854097\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.2443056981277167\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.3053086072600357\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.2919095132069827\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.1115280585919534\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.159393232101909\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.3068843372336825\n",
      "Training epoch 7 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.1601961652315085\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.134267017824359\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.224728367543039\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.143250253902068\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.1884546227853923\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.247150561557755\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.1519695347610663\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.273130666698459\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.2476097408171016\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.2296591033920494\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.1909104694713677\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.2118049704403697\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.2579463761999734\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.1843505726826935\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.21551240425772\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.2318602064265156\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.17404836052714\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.1174927410538396\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.244653450078156\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.1768739050650847\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.210585440347238\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.1528705341247574\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.206196775236868\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.2042115085904443\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.1772123160180414\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.203801841515523\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.281347081252375\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.26140498781235\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.0840934410916883\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.1253535656838087\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.2958087473750477\n",
      "Training epoch 8 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.1275195614283455\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.102286425185767\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.181880438571099\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.09389849342851\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.1503459077559226\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.2190330809219923\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.112040700422545\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.225066253126703\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.2258714491754974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.1932707473803843\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.1534784776214004\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.173586412656976\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.2259004422559134\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.1562008826015804\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.172883565453288\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.1955388921845866\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.132555055037241\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.082325844150579\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.2106337884939995\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.1376621715519155\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.1843027492298113\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.1144488868761235\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.167029280976662\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.1640529382284206\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.1384672600222565\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.163958950924248\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.2565557014954103\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.2260472638833235\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.041020059248445\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.083385666108772\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.2813898584144416\n",
      "Training epoch 9 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.087258575600381\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.0615843949026122\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.1349023228685073\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.043446304564367\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.1067210463613484\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.1856603357481807\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.0698113935220683\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.1802663568671248\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.199043249172357\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.148635377687543\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.1108529640811855\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.13185209066745\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.1900871811553886\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.1186970140049075\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.13003972505152\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.155416332143903\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.086546603288284\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.0365163173448453\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.1696371870258373\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.09244182639763\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.150479246045661\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.063412738303275\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.123975055468959\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.1166439110831794\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.091870757076547\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.119147647780522\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.227209354418716\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.1840959865361205\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.9844940137303475\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.0316257428863898\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.2610949644668143\n",
      "Training epoch 10 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.0381401257097345\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.011309907610149\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.079696603318599\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.9867862761435227\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.0543479131668443\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.1448914150710046\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.021198158799496\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.131267498647707\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.1649589036775425\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.0939986229188814\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.060642188369434\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.082198566504067\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.147294391560961\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.071183278880901\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.081036976308413\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.107834193979552\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.0320856290313913\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.9801436611295213\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.1198752846452598\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.0386422554813315\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.1078178746907787\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.9997865819880964\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.0732519879357207\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.0597771162504523\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.035458366742032\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.066284038428045\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.1914633471552554\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.1335857021576268\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.9151096206213822\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.9689256742845327\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.2332558722148854\n",
      "Training epoch 11 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.978952324034632\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.9506095702202075\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.013875334594803\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.9211027844757163\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.9909847499014937\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.0949569591849646\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.9637539041428353\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.0738093360629994\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.1217673120325538\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.0275057295279617\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.0009792680636407\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.021837878268511\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.0951399277795693\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.012524427429555\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.022242214782675\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.0498838557180488\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.9665676979172986\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.9127985539057355\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.0595284028846366\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.9741451869946807\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.0549861902553546\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.9227796775846806\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.012320616531749\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.9915573920314287\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.9673942922506904\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.0032186169670374\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.147786660402878\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.0725308673506064\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.8327618012790956\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.8942007592823251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.196001882998258\n",
      "Training epoch 12 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.9085233928366627\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.8785907814893037\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.935650313374392\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.8446526405429355\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.9148060815550791\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.0342155663667802\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.8956964116880606\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.004932284932065\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.0675830944350118\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.9473701210929473\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.9303265135634153\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.9486275113778473\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.031585343074086\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.9414171854627562\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.9510126080307295\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  1.979093811119591\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.8881485555767945\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.8340132297295106\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.9868432230380975\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.8971787576219277\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.990571556019388\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.8315539103541147\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.9392534577781233\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.9104768781449184\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.8861442349566062\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.9284304951451048\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.094796304130381\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.9991223392500348\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.7374770700574467\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.8066803886139922\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.1471785749701273\n",
      "Training epoch 13 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.8260087050211404\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.7946652654518627\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.843849194789933\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.756563743788415\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.8245390994839226\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.9613468004397354\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.8157782401564337\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.9225033312462112\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.000676197375133\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.8522576737404006\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.8476139717686735\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.8610814987864033\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.9549938393891382\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.8568477234084941\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.8654692499660428\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  1.8934979702088337\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.795824508659861\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.7437285766532582\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.9004184654271974\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.806492128066561\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.913396005962707\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.7259050442440482\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.8527779761111067\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.8157588587977584\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.7908278851743742\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.8411815669893765\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.031429190359114\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.9120263480951565\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.630109807581214\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.706345341285023\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.084535227598979\n",
      "Training epoch 14 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.7312818009649575\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.698963786130419\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.7382686587793543\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.6570318404121316\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.7198688737230008\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.8757247339450474\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.7234524886852554\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.8253104593624676\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  1.9198452155724144\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.741808271207025\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.7525443156676477\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.7587286772661748\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.8644239770744506\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.7586074589774234\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.7647348355452557\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  1.791983663340924\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.6897931411966922\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.6427269415198051\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.7996123009868512\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.701704663111935\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.8229438643689568\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.6068842093209283\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.752596625722812\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.7078230920775368\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.6816947476657895\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.741853795926469\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  1.9572176926989795\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.810789019083772\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.5128500747651192\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.5943628349201184\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.0061027050725113\n",
      "Training epoch 15 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.625337614583683\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.592721334817227\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.6201117761124189\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.5476261938539166\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.6019206995932875\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.777867512570284\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.619152370430686\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.7134131991976655\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  1.8248922574299535\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.6171990912803367\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.6459553650718939\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.6425648801352257\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.760034413995313\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.6477926729289691\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.6493931076980637\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  1.6748196092294982\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.5718537601458762\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.5329361472642415\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.6850017979651781\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.5837386062292245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.719812349425793\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.4772231830311653\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.639794886954088\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.588707066494035\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.5606029818473341\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.6322604072001852\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  1.8725616634635536\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.696274530175184\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.3893508758328008\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.4733330332353407\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  1.9107950990449332\n"
     ]
    }
   ],
   "source": [
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 42  4  1  2  2  2  0  0  2]\n",
      " [ 1  4 46  0  0  0  0  1  0  0]\n",
      " [ 1  3  7 41  0  0  0  2  2  0]\n",
      " [ 2  3  0  0 57  0  0  2  0  0]\n",
      " [ 2  4  0 19 13  3  1  5 22  4]\n",
      " [ 1  0  0  0  0  0 55  1  0  0]\n",
      " [ 1 23  2  1 10  0  0  7 15  3]\n",
      " [ 0  6  8 10  1  0  5  8 13  1]\n",
      " [ 1 10  1  3  0  3  0 12  5 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92        55\n",
      "           1       0.44      0.76      0.56        55\n",
      "           2       0.68      0.88      0.77        52\n",
      "           3       0.55      0.73      0.63        56\n",
      "           4       0.68      0.89      0.77        64\n",
      "           5       0.38      0.04      0.07        73\n",
      "           6       0.87      0.96      0.92        57\n",
      "           7       0.18      0.11      0.14        62\n",
      "           8       0.23      0.25      0.24        52\n",
      "           9       0.77      0.49      0.59        68\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       594\n",
      "   macro avg       0.56      0.61      0.56       594\n",
      "weighted avg       0.56      0.59      0.55       594\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true, y_pred = model1.test()\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ModelSpec2(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  3.098883527740903\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  3.1357391399245182\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.8388243352364024\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.7062256948850054\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.9583091345818913\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.884824170129061\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.504345945598444\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  2.385751442560701\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.90509853024379\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.9180359004067427\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  2.5282201123008106\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  2.4696211856474166\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  2.425799447032778\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.8984727013797595\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  2.1857909797484725\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.6212834279602832\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  2.3416594632244907\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.7006937610554473\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.682517379480533\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  2.3523136308849075\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.585899345382446\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  2.6480334098804272\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  2.246719900985107\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  2.2741204523712852\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  2.4079265095243345\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.3356166978319957\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.531794577445214\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  2.087570438750818\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  2.5211632272651867\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  2.205688149106842\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  2.136028871198276\n",
      "Training epoch 2 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  2.199068130415321\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  2.3604221483526677\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  2.1638985871872802\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  2.1359398519656967\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  2.1959920057181663\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  2.171213167078244\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  2.067361920583156\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.9380491032285878\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  2.196709056307295\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  2.1626359751267983\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.9401108404792886\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.9913837291074141\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.9610544030122345\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  2.165658550081808\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.8472378628359152\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  2.006980611796228\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.910366161507912\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  2.074962451947589\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  2.077302022002519\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.842683314362843\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  2.0403827231469434\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.998342495114533\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.8994466846708504\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.7932996514672008\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.8886960783200955\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  2.002985512119428\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  2.1044995668375948\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.678467485612746\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.9599663822241546\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.7607278799586468\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  1.59148305578272\n",
      "Training epoch 3 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.776179330027721\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.956595751181937\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.8023307912030275\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.7885105307116398\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.722292005904741\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.7851847814183195\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.8034176765441656\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.634653746104251\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  1.8046170587057577\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.72318377384723\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.5952531401873706\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.627177509449399\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.656176788273464\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.7142130656460282\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.5622808276408524\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  1.5987644754657517\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.5729686675681362\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.6828683795735657\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.6794827725074364\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.5126525694857942\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.6861117069778149\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.5435023248385087\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.5980210176583074\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.441799009145454\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.5309431617462246\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.710270540647948\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  1.7702107919740506\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.3669664566064355\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.5300209024163043\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.3932408990080316\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  1.2633665041279325\n",
      "Training epoch 4 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.468538560844026\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.6253873596712531\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.4813258322301397\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.5010718312150646\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.3291664934530694\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.4828763896113464\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.541153131697132\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.3551462308987137\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  1.4821772945716332\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.3843301607864613\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.3029703539796824\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  1.2876861458943518\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.3865238790400287\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.3642853596800841\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.2781079888144553\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  1.2632463628368258\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  1.2621749884888678\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.3781127443770256\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.3531914574499626\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  1.2278295705041946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.395114893011451\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  1.1708300497142754\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.3074064533921377\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  1.143243158462361\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  1.2360817956068892\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.4349033718319348\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  1.4665894895977691\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  1.0881226306521523\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  1.1627617771095216\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  1.07363557956958\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  1.0047757532944583\n",
      "Training epoch 5 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  1.2051032605655876\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.3306750727902716\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  1.191112667144514\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.2496013303452478\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  1.0028343183988628\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.2315725211230717\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.2846231783249027\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  1.1039425840675903\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  1.211395502826035\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  1.108652863671502\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  1.0497344180573827\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.997011876676174\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  1.1468431403983406\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  1.0806278895134755\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  1.0235182712449\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.9907448907830624\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.9970699782376002\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  1.1271221313466355\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  1.0821511767328116\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.9798976510326984\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  1.146263573941196\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.8841343384717236\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  1.050408446843099\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.9019415717414283\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.9992941835188344\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.198554943048525\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  1.2042196574724957\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.853939585608431\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.862748464203062\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.8222303251100946\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.7904411933158721\n",
      "Training epoch 6 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.9874477349333155\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  1.0864566161369347\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.9512058146841138\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  1.0456612716084934\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.7558871493336486\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  1.0376609755932198\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  1.0573587429678284\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.8986375349682936\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  1.0021966146519277\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.8968082678436037\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.8469925570992167\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.7734822750714496\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.9490645934467963\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.8645266076840633\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.8181080380614422\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.7840277900291797\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.7906072625558934\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.9295686343611707\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.8700917585400848\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.7782719802954102\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.9430398447304824\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.6845863154942239\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.8438479173424781\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.7207415698135058\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.8207952159517202\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  1.0096342976066943\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.9940125421000706\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.6716021549454458\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.6350776322275047\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.6416496554213504\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.6239031052619931\n",
      "Training epoch 7 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.817814300306653\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.8970306021101955\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.7670686614092753\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.8907404783428934\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.5793281411932389\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.8982902974924822\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.8733379358730613\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.7412634585667929\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.8475630694598429\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.7410839925600258\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.6936404207733976\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.611738885442982\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.7961907892010777\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.706674773092169\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.6638325026535451\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.6310930786320983\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.6377785497379167\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.7802956810391231\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.7107828518346349\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.6227696748644256\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.7848275612750737\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.5509066899825334\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.6877370338515185\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.5893316646004239\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.690525092878228\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.8650475596383191\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.833887892099195\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.5354223192406817\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.47170692918345924\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.5172912407594851\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.49990081099599254\n",
      "Training epoch 8 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.6890800955873644\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.7537311661770761\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.6317562490336751\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.7761572626615936\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.454472879234107\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.801255519161532\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.7319594999895276\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.6234175408408216\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.7332374943222675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.6286252688652638\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.5806650188352933\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.49640069625563576\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.6815440703714453\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.5927042954508035\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.5520462988669232\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.5176985417339623\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.526671622557871\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.6693382097360557\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.5931541536972066\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.5060267328999444\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.6651118204913091\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.4604607781517146\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.572346659570006\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.4941855713646398\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.596094963966102\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.7567925861206504\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.714606987013011\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.4352870866604956\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.3583757582479928\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.4318983804250151\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.4079381945546181\n",
      "Training epoch 9 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.5917422197494527\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.6448847853734243\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.5338384372275472\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.6912602636885913\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.36536649338369437\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.7334535785494467\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.6250494405389888\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.5347190415246763\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.6475953727987871\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.5473613283125716\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.4976073448245749\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.4131623067421698\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.5955433936766003\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.5102935222778985\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.47149488650253585\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.43271942491033577\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.44547598860054893\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.5867988431625376\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.5062179146298253\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.4190395439453366\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.575342685149502\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.397273577452746\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.48654479465751965\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.42435520045813285\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.5270642236177284\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.6760726201174789\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.625612928561709\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.3617014743471899\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.28039914403249355\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.3719353885419642\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.3389479974774396\n",
      "Training epoch 10 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.5176404949029425\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.5606594788892449\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.4624164445223749\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.6272866967073438\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.3006855339548754\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.6848178851224406\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.543765015953747\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.46665020972142573\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.5825555983126052\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.48759099065130485\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.4356292851680907\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.35158975929265907\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.5300328184549252\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.4502631086627794\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.41263617321646595\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.36808255632645726\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.38500244437553727\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.5247923562717226\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.44103357254331027\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.3539066888339319\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.5075691759720865\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.3513366228726446\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.42150485922035097\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.3720395614919068\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.4756633094291086\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.6154158412028665\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.5581691843280858\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.3071513902870361\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.22608085503644376\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.32835956476551276\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.2864389092233714\n",
      "Training epoch 11 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.4604770553123726\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.49398248791284677\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.4091510267534556\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.5780095129161295\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.25274284265875213\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.6485959464985169\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.4810584432392308\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.4131654600631876\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.5324226162855654\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.44233368334442974\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.3883292399119793\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.3046951479730077\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.479159448890916\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.40600500503126924\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.3686518880915026\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.3180841575071741\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.33885773392690177\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.4775344615783809\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.3910821291811142\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.3045436649136004\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.45548697842525476\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.31662810413710984\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.3710665297565107\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.331910708336813\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.4364807894820421\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.569156566824858\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.5060078868677353\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.26612642521553936\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.1873254817172981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.2954999925790492\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.24587474611239638\n",
      "Training epoch 12 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.41557960419265816\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.44000726753840524\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.36833536227025937\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.539204003569464\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.2163836783045076\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.620489003329627\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.4318134156597223\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.3701586721070048\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.49312142497997796\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.406964699218079\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.35136150697727836\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.26795233034238836\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.43891341559490604\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.37284904329792135\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.3349701341737747\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.278743649978319\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.3027672758960689\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.4409153490014511\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.3518753685404857\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.26654386307689454\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.41453398057145074\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.2895242043690872\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.3310718105410092\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.30040001771198943\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.4058865609222032\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.5332011018041382\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.4648581349054224\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.234741198880816\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.1588749655130372\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.2698441079458432\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.2140623633492773\n",
      "Training epoch 13 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.3795839838573804\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.39542618689722664\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.33623693765456714\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.508005750648929\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.18816394293763644\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.5977915510403298\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.39241404339850944\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.33484425228882914\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.4617448336006763\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.37852720089073333\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.3218155077751536\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.23844567516831533\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.40654497054232086\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.34754463929674145\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.3085616422175758\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.24727955061883233\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.2738844994144831\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.4120468939805838\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.3203863083496079\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.23679978938918653\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.38155969174858806\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.2677871092674096\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.2987052646766701\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.27511828978279984\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.3814655604727518\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.5046610210161263\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.43182148424937383\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.2102983162165768\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.13737957544053914\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.24918959983434918\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.18873464557527542\n",
      "Training epoch 14 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.3501177833642378\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.3579594734756751\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.3104233891181944\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.48244202075815823\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.16577546679081312\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.5787871620542278\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.3603137732826093\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.3053057498099111\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.43622508628332424\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.3551260743928113\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.297721394861012\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.21426963167969165\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.3801371184142627\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.3278454304379083\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.28739949055386543\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.2217297613980429\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.25029136843497113\n",
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.38889781626256564\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.29456857076493864\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.21313429882265975\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.3544189476758369\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.24998159068895004\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.27203110586666435\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.25444321505349987\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.36158911587680975\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.48152103716508793\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.40489497933696583\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.19092626595198267\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.12069559384629044\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.23212232225467985\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.1682716355147563\n",
      "Training epoch 15 of 15.\n",
      "Training batch of inputs between 0 and 40.\n",
      "Loss:  0.3255217613494795\n",
      "Training batch of inputs between 40 and 80.\n",
      "Loss:  0.3260119888830616\n",
      "Training batch of inputs between 80 and 120.\n",
      "Loss:  0.2892769945087395\n",
      "Training batch of inputs between 120 and 160.\n",
      "Loss:  0.4611269004213865\n",
      "Training batch of inputs between 160 and 200.\n",
      "Loss:  0.14765583353741144\n",
      "Training batch of inputs between 200 and 240.\n",
      "Loss:  0.5623690087001411\n",
      "Training batch of inputs between 240 and 280.\n",
      "Loss:  0.333708721483886\n",
      "Training batch of inputs between 280 and 320.\n",
      "Loss:  0.2801995523043629\n",
      "Training batch of inputs between 320 and 360.\n",
      "Loss:  0.41508742062885995\n",
      "Training batch of inputs between 360 and 400.\n",
      "Loss:  0.33551463947173255\n",
      "Training batch of inputs between 400 and 440.\n",
      "Loss:  0.2777199323749424\n",
      "Training batch of inputs between 440 and 480.\n",
      "Loss:  0.19414340040270123\n",
      "Training batch of inputs between 480 and 520.\n",
      "Loss:  0.35832487169259875\n",
      "Training batch of inputs between 520 and 560.\n",
      "Loss:  0.31219517801604324\n",
      "Training batch of inputs between 560 and 600.\n",
      "Loss:  0.27010368128696577\n",
      "Training batch of inputs between 600 and 640.\n",
      "Loss:  0.20069143819762783\n",
      "Training batch of inputs between 640 and 680.\n",
      "Loss:  0.23067106145899716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch of inputs between 680 and 720.\n",
      "Loss:  0.3700262083110413\n",
      "Training batch of inputs between 720 and 760.\n",
      "Loss:  0.2730178091692242\n",
      "Training batch of inputs between 760 and 800.\n",
      "Loss:  0.194014252603245\n",
      "Training batch of inputs between 800 and 840.\n",
      "Loss:  0.3316413619165182\n",
      "Training batch of inputs between 840 and 880.\n",
      "Loss:  0.2351488521349981\n",
      "Training batch of inputs between 880 and 920.\n",
      "Loss:  0.24969334960990075\n",
      "Training batch of inputs between 920 and 960.\n",
      "Loss:  0.23724983776287542\n",
      "Training batch of inputs between 960 and 1000.\n",
      "Loss:  0.34513224755889305\n",
      "Training batch of inputs between 1000 and 1040.\n",
      "Loss:  0.4623757319180357\n",
      "Training batch of inputs between 1040 and 1080.\n",
      "Loss:  0.3826585160304621\n",
      "Training batch of inputs between 1080 and 1120.\n",
      "Loss:  0.17531675922288945\n",
      "Training batch of inputs between 1120 and 1160.\n",
      "Loss:  0.10742830727476922\n",
      "Training batch of inputs between 1160 and 1200.\n",
      "Loss:  0.21770721231422568\n",
      "Training batch of inputs between 1200 and 1240.\n",
      "Loss:  0.15150852789816782\n"
     ]
    }
   ],
   "source": [
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 47  5  0  1  0  0  0  2  0]\n",
      " [ 0  1 50  0  0  0  0  0  1  0]\n",
      " [ 0  0  1 49  0  1  0  0  4  1]\n",
      " [ 1  0  0  0 59  0  1  1  1  1]\n",
      " [ 0  0  0  1  1 62  3  0  0  6]\n",
      " [ 0  0  0  0  0  2 54  0  1  0]\n",
      " [ 2  0  0  0  0  2  0 58  0  0]\n",
      " [ 0  4  0  1  0  0  0  0 47  0]\n",
      " [ 0  0  0  1  0  1  1  2  2 61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        55\n",
      "           1       0.90      0.85      0.88        55\n",
      "           2       0.89      0.96      0.93        52\n",
      "           3       0.94      0.88      0.91        56\n",
      "           4       0.97      0.92      0.94        64\n",
      "           5       0.91      0.85      0.88        73\n",
      "           6       0.92      0.95      0.93        57\n",
      "           7       0.95      0.94      0.94        62\n",
      "           8       0.81      0.90      0.85        52\n",
      "           9       0.88      0.90      0.89        68\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       594\n",
      "   macro avg       0.91      0.91      0.91       594\n",
      "weighted avg       0.91      0.91      0.91       594\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true2, y_pred2 = model2.test()\n",
    "plot_confusion_matrix(y_true2, y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
